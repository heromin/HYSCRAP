name: ðŸŽ¬ Scraper de Animes

on:
  schedule:
    # Ejecuta todos los dÃ­as a las 2:00 AM (UTC)
    - cron: '0 2 * * *'
  
  # Permite ejecutar manualmente desde GitHub
  workflow_dispatch:
    inputs:
      anime_name:
        description: 'Nombre del anime'
        required: false
        default: ''
      tmdb_id:
        description: 'ID de TMDB'
        required: false
        default: ''

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.10']

    steps:
      - name: ðŸ“¥ Descargar cÃ³digo
        uses: actions/checkout@v4

      - name: ðŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: ðŸ“š Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: ðŸš€ Ejecutar scraper
        env:
          ANIME_NAME: ${{ secrets.ANIME_NAME }}
          TMDB_ID: ${{ secrets.TMDB_ID }}
          API_URL: ${{ secrets.API_URL }}
          API_TOKEN: ${{ secrets.API_TOKEN }}
        run: python scraper.py

      - name: ðŸ“§ Notificar si falla
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: 'âŒ El scraper fallÃ³. Revisa los logs.'
            })

      - name: ðŸ“ Crear resumen
        if: always()
        run: |
          echo "## ðŸŽ¬ Scraper Execution Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Executed at**: $(date)" >> $GITHUB_STEP_SUMMARY
